---

layout:     post
title:      Bayes学习
subtitle:   第一节课
date:       2020-01-19
author:     HYQ
header-img: img/post-bg-universe.jpg
catalog: true
tags:

   - 数学
        - Bayes
            - Notes

---

# Bayes 学习的第一节课



## 导论和例子



### 什么是Bayes method



#### 性质功能

-  Bayes inference ： 通过information 来更新 belief 的归纳learning 的process 
-  提供超越归纳的性质：
  - 具有良好统计特性的参数估计
  - 对观测数据的简洁描述
  - 对缺失数据的预测和对未来数据的预测
  - 模型估计、选择和验证的计算框架

> Statistical induction（统计归纳）：从小样本的性质来估计大样本的过程，小样本subset：为 $y$，想估计的大样本参数为  $θ$ 

 

#### goal:   

-  by subset information to decrease the uncertainty of big data  information



#### 定义空间

- 样本空间 $Y$
- 参数空间  $$Θ$$



#### 三要素

- *prior distribution* 先验分布：$p(θ)$  代表我们最开始的belief ，每个参数取值等于总体的真实参数取值的概率
- *sampling model*：$p(y|θ)$  在我们相信 $θ$ 为真时（ $θ$ 为真的条件下），进行一次试验样本空间中每个$y$ 取到的概率
- *posterior distribution:*  $p(θ|y)$ 在我们得到 $y$ 的information 后update后 ，参数空间内每个参数取值等于总体的真实参数取值的概率



#### 要素的链接，update的rule



![](Bayes 学习的第一节课.assets/捕获.PNG) 

- $y$  :   已知的随机变量，由  $p(y)$ 刻画
- $θ$  ：随机变量，由 $p(θ)$  刻画
- $$\tilde{θ}$$   :  随机变量在参数空间内每一个具体的取值，为常数





### **Why Bayes**

> Bayes rule 为其统计归纳提供了理论依据

- $p(θ)$ 的选择由于

  - 方便取值

  - 计算方便

> $all \ \ \ models\ \ \  are \ \ \ wrong, \ \ \ \  but \ \ \ some \ \ \   are \ \  \ \ useful$



- $p(θ|y)$ 可以很好的代表我们在$y$ 下的对总体的近似
- 当我们对data是 如何在不同的先验分布情况下update belief 时很有用
- 特别对于先验信息量较少时 的update 感兴趣：先验分布在参数空间中跨大部分区域，较为分散
- 最后，在许多复杂的统计问题中，没有明显的非贝叶斯估计或推理方法
  - 在这种情况下，贝叶斯规则可以用来生成估计过程
  - 这些程序的性能可以用非贝叶斯标准来评估
  - 贝叶斯或近似贝叶斯程序工作得很好，即使对于非贝叶斯的目的也是如此



#### 估计罕见事件发生的概率

- 调查流行病，来定下监管力度
  - 抽样20人
  - 样本空间 （患病人数）$Y$ ：{0，1，2，……，19，20}
  - 参数空间  （城市中感染者的比例）$$Θ$$： [0*,* 1] 
  - 抽样模型 $p(y|θ)$  ：$$ Y|θ ∼ binomial(20, θ)$$  假设满足二项分布
- 先验分布
  - 来自全国各地的其他研究表明，可比城市的感染率约为0.05至0.20，平均流行率为0.10
  - 对$θ$ 建模其实是对这个城市中抽取一人患病的概率进行建模
  - 我们给(0.05, 0.20)分配大量概率，并使其$E(θ)$ 等于 0.10
  - 然而，有无限多的概率分布满足这些条件，目前还不清楚我们是否可以用有限的先验信息来区分它们
  - 因此，我们将使用具有上述特性的先验分布 $p（θ）$,  但其特定的数学形式是为了计算方便而选择的
  - 我们选择Beta 分布

> Beta 分布 tip
>
> 为一无所知的时候从过往数据对概率进行建模的分布函数
>
> 假设过往数据为二项分布，因为一无所知假设先验为[0,1]均匀分布（成功一次，失败一次）
>
> 最后得到的分布为Beta 分布
>
> 参数a：p实现的次数，为1 + 过往数据的成功值
>
> 参数b：p未实现的次数，为1+ 过往数据的失败值
>
> Beta分布的后验分布还是Beta分布，参数a= a1 + 成功次数，b = b1 + 失败次数
>
> ![](Bayes 学习的第一节课.assets/捕获2.PNG)
>
> 分母是常数
>
> $E(θ) = a/(a + b)$
>
>  *θ* 的最可能值：  (*a* -1)*/*(*a-* 1 + *b* -1)

- ***θ* ∼*beta(2*, 20)**
- ***θ|{Y* = 0*}* *∼* beta(2*,* 40)**：为我们提供了一个了解全市感染率θ的模型
- 迭代后 beta分布的峰值上升，代表更多的数据给了我们更多的belief



- 灵敏度分析

  - 假设a，b取任意值
  - ![](Bayes 学习的第一节课.assets/捕获3.PNG)
  - 可以得出，最后的期望为：（过去试验数+1）与 Y试验数 在（总试验数+1）占的比例为过去和当前likehood估计的参数的权重 ，w为先验置信度
  - $$ a = wθ_0 \  \ \ b = w(1-θ_0) \  \ \ beta(wθ_0 + y, w(1-θ_0)+n-y)$$
  - 关于$w，wθ_0$， 可以做出$E[θ|Y = 0] and Pr(θ < 0.10|Y = 0)$ 值的等高线图
- ![](Bayes 学习的第一节课.assets/捕获4.PNG)
  
- 与非Bayes方法比较
  - 估计值为likehood  = 0
  - ![](Bayes 学习的第一节课.assets/捕获5.PNG)
  - 计算得出结果为0，即使包括99%的置信区间，得出的结论是有样本偏差的



- 使用Bayes 的方法来做区间估计
  - ![](Bayes 学习的第一节课.assets/捕获6.PNG)
  - 先验分布为：beta(2,2)
- 总体均值的一般估计
  - ![](Bayes 学习的第一节课.assets/捕获7.PNG)
  - 在大样本情况下这个估计值与y的likehood一样，小样本时利用对先验的确定来消除对样本的不确定
  - 即使一个特定的先验分布p（θ）不能准确地反映我们的先验信息，相应的后验分布（posterior）仍然可以作为提供稳定推理的有用手段以及对样本量低的情况的估计



#### 建立预测模型

- 糖尿病进展的预测模型：64个变量，342个样本，做回归模型，使用100样本test模型表现
- 采样模型和参数空间
  - 采样模型：![](Bayes 学习的第一节课.assets/捕获8.PNG)
  - **β** = (*β*1*,* *. . .* *, β*64) 加上*σ* ：参数空间
- 先验分布：
  - 定义一个65个参数的联合随机变量，并准确的求出先验估计值太难了
  - 作为另一种选择，我们将使用一个先验分布，它只代表我们先前信念的某些方面
  - 我们想表达的主要信念是，64个解释变量中的大多数对糖尿病的进展几乎没有影响：大多数回归系数为零
  - 每个回归系数有50%的先验概率等于零
- 后验分布：
  - ***p*(β|*y*, X)** ：计算每个回归系数不等于0的概率，发现0数急剧上升
- 预测性能与非贝叶斯方法的比较
  - ![](Bayes 学习的第一节课.assets/捕获9.PNG)
  - ![](Bayes 学习的第一节课.assets/捕获11.PNG)
  - 故此得到预测值计算与测试集的均方误差和，比Bayes结果要糟糕，因为受到了小样本中的噪声影响
  - lasso为另一种稀疏化的方法
    - ![](Bayes 学习的第一节课.assets/捕获12.PNG)
    - 它对应于使用特定先验分布的贝叶斯估计：拉普拉斯分布（双指数分布）

### **Where we are going**

- 理性、定量学习的模型
- 适用于小样本和大样本的估计器
- 在复杂问题中生成统计程序的方法
- 第二章：概率
- 第3，4章：单参数统计模型
- 第5，6，7章：多元正态分布的Bayes
- 之后：层次模型，混合模型，回归，广义线性模型……





## 信念，概率，可交换性

> - 信念函数和概率的性质
> - 离散和连续随机变量及分布
> - 独立性与可交换性的关联



### **Belief functions and probabilities**

- 概率：通过数字表达理性信念的方法
- 我们希望数值信念与概率有一些同样的性质
  - 存在三个状态：
    - F={某人投票给左派候选人}
    - G={一个人的收入在人口的最低10%}
    - H={一个人住在一个大城市}
  - Be() ：*belief function* 给状态一个数值，越高代表越相信（用偏好代替赌）
  - Be（F）>Be（G）意思是我们宁愿赌F是真，也不愿赌G是真
  - Be(*F**|**H*) *>* Be(*G**|**H*)  这意味着，如果我们知道H是真的，那么我们宁愿打赌F也是真的，而不是打赌G也是真的
  - Be（F|G）>Be（F|H）的意思，如果我们被迫赌F，我们宁愿在G是真而不是H是真的条件下做这件事
- 信念的公理
  - **B1** Be(not *H**|**H*) *≤* Be(*F**|**H*) *≤* Be(*H**|**H*)
  - **B2** Be(*F* or *G**|**H*) *≥* max*{*Be(*F**|**H*)*,* Be(*G**|**H*)*}*
  - **B3** Be(*F* and *G**|**H*) can be derived from Be(*G**|**H*) and Be(*F**|**G* and *H*)
- 概率公理
  - **P1** 0 = Pr(not *H**|**H*) *≤* Pr(*F**|**H*) *≤* Pr(*H**|**H*) = 1
  - **P2** Pr(*F* *∪* *G**|**H*) = Pr(*F**|**H*) + Pr(*G**|**H*) if *F* *∩* *G* = *∅*
  - **P3** Pr(*F* *∩* *G**|**H*) = Pr(*G**|**H*) Pr(*F**|**G* *∩* *H*)
- 故此一个概率函数应该也满足信念公理



### **Events, partitions and Bayes** **rule**

- **Partition分区**：一个集合*$H$* 的分区 $\{H_1,H_2,......H_i\}$  是一系列不相交的集合的集合，这些集合的并为$H$
- *Partitions and probability*：
  - 如果$\{H_1,H_2,......H_K\}$ 是$H$ 的分区，且 $Pr(H)  = 1$，E是某些特定的事件
  - ![](Bayes 学习的第一节课.assets/捕获14.PNG)

  - 这种计算方法提醒我们，Bayes的规则并不能确定我们看到数据后的信念应该是什么，它只能告诉我们看到数据后他们应该如何改变



###  **Independence**

> - Pr(*F* *∩* *G**|**H*)  = Pr(*F**|**H*) Pr(*G**|**H*)
>
> - Pr(*F**|**H* *∩* *G*) = Pr(*F**|**H*)
> - 等价于 F,G 独立



### **Random variables**

- 离散随机变量
  - ![](Bayes 学习的第一节课.assets/捕获15.PNG)
  - 大Y 的可能值是可数的
- 连续型随机变量：略，概率分布：略，联合分布：略



